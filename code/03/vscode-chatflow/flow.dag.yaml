id: template_chat_flow
name: Template Chat Flow
environment:
  python_requirements_txt: requirements.txt
inputs:
  question:
    type: string
    default: what is onelake
outputs:
  answer:
    type: string
    reference: ${chat.output}
    is_chat_output: true
nodes:
- name: question_embeddings
  type: llm
  source:
    type: code
    path: question_embeddings.jinja2
  inputs:
    deployment_name: TextEmbeddingsModel
    input: ${inputs.question}
  connection: AOAIConn
  api: embedding
- name: search_kb
  type: python
  source:
    type: code
    path: search_kb.py
  inputs:
    cogconn: AzureCogSearch
    questionvector: ${question_embeddings.output}
  aggregation: false
- name: answer
  type: llm
  source:
    type: code
    path: answer.jinja2
  inputs:
    deployment_name: GPTModel
    temperature: 0.2
    answer: ${search_kb.output}
    max_tokens: 13000
  connection: AOAIConn
  api: chat
- name: chat
  type: llm
  source:
    type: code
    path: chat.jinja2
  inputs:
    deployment_name: GPTModel
    temperature: 0.1
    question: ${inputs.question}
    answer: ${answer.output}
  connection: AOAIConn
  api: chat
